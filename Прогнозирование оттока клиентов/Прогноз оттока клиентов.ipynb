{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span></li><li><span><a href=\"#Исследование-моделей-без-учета-дизбаланса\" data-toc-modified-id=\"Исследование-моделей-без-учета-дизбаланса-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Исследование моделей без учета дизбаланса</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дерево-решений-1.0\" data-toc-modified-id=\"Дерево-решений-1.0-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Дерево решений 1.0</a></span></li><li><span><a href=\"#Случайный-лес-1.0\" data-toc-modified-id=\"Случайный-лес-1.0-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Случайный лес 1.0</a></span></li><li><span><a href=\"#Логистическая-регрессия-1.0.\" data-toc-modified-id=\"Логистическая-регрессия-1.0.-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Логистическая регрессия 1.0.</a></span></li><li><span><a href=\"#Выводы-по-исследованию-моделей-без-учета-дизбаланса\" data-toc-modified-id=\"Выводы-по-исследованию-моделей-без-учета-дизбаланса-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Выводы по исследованию моделей без учета дизбаланса</a></span></li></ul></li><li><span><a href=\"#Борьба-с-дизбалансом\" data-toc-modified-id=\"Борьба-с-дизбалансом-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Борьба с дизбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Взвешивание-классов\" data-toc-modified-id=\"Взвешивание-классов-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Взвешивание классов</a></span></li><li><span><a href=\"#Upsampling\" data-toc-modified-id=\"Upsampling-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Upsampling</a></span></li><li><span><a href=\"#Downsampling\" data-toc-modified-id=\"Downsampling-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Downsampling</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Тестирование модели</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import f1_score #(y_true, y_pred)\n",
    "from sklearn.metrics import confusion_matrix #(y_true, y_pred)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В столбце Tenure (сколько лет человек является клиентом банка) у нас есть NaN значения. Они составляют меньше 10% данных, так что просто отбросим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фамилии клиентов с большой вероятностью не влияют на их банковскую активность, а в случае применения One hot encoding (прямое кодирование) этот столбец превратится в тысячу лишних переменных. Удалим его, а потом применим One hot encoding ко всей таблице, чтобы преобразовать остальные категориальные признаки в численные. Таких категориальных переменных останется две - страна (Франция, Испания и Германия) и гендер (муж., жен.). \n",
    "\n",
    "Так как индекс строки с изначальных данных и идентификационный номер клиента по факту не должны влиять на целевой признак, отбросим их в финальной таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Surname', axis = 1)\n",
    "df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "df_ohe = df_ohe.drop(['RowNumber', 'CustomerId'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ohe.head())\n",
    "df_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также видим, что некоторые параметры, например, Balance и EstimatedSalary принимают гораздо большие значения, чем все остальные. Исправить это поможет масштабирование признаков через стандартизацию данных. Перед этим разобьем данные на параметры и целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ohe.drop(['Exited'], axis=1)\n",
    "target = df_ohe['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features,target, test_size=0.4, random_state=RANDOM_STATE)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid,target_valid, test_size=0.5, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train) #fitting scaler to train features\n",
    "features_train = pd.DataFrame(scaler.transform(features_train)) #scaling train features\n",
    "features_valid = pd.DataFrame(scaler.transform(features_valid)) #scaling valid features\n",
    "features_test = pd.DataFrame(scaler.transform(features_test)) #scaling test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.columns = features.columns\n",
    "features_valid.columns = features.columns\n",
    "features_test.columns = features.columns\n",
    "features_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае у нас есть два класса в целевом признаке, то есть мы решаем задачу классификации, а не предсказания. Таким образом, нам здесь понадобятся модели классификаторы: возьмем дерево решений, случайный лес и логистическую регрессию.\n",
    "\n",
    "В качестве метрик успешности модели возьмем ***F1***, объединяющую в себе точность и полноту (***precision** = true positives/all predicted positive и **recall** (он же true positive rate) = true possitives/all ground truth positives), и area under the curve of ROC (receiver operating characteritic - то есть функция отношения ***true posititive rate*** к ***false positive rate***). \n",
    "\n",
    "Чем выше F1 (*= (2 * Precision * Recall) / (Precision + Recall*), тем лучше баланс модели между полнотой и точностью. \n",
    "\n",
    "Чем больше область под функцией ROC, тем успешнее модель.\n",
    "\n",
    "Метрики mean absolute error и mean squared error нам здесь не понадобятся, так они оценивают качество регрессии-предсказателя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на баланс классов \n",
    "\n",
    "target_train.sum()/len(target_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим значительный дизбаланс классов в целевом признаке - ответы 1 составляют всего 20% данных. Сперва попробуем обучить модели без учета дизбаланса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование моделей без учета дизбаланса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опробуем три модели классификатора:\n",
    "    \n",
    "    - Дерево решений (DecisionTreeClassifier)\n",
    "    - Случайный лес (RandomForestClassifier)\n",
    "    - Логистическая регрессия (LogisticRegression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_model = None\n",
    "best_tree_result = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 15):\n",
    "    model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=depth) #опробуем глубину дерева от 1 до 15\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid) \n",
    "    result = f1_score(target_valid, predictions)\n",
    "    if result > best_tree_result:\n",
    "        best_tree_model = model\n",
    "        best_tree_depth = depth\n",
    "        best_tree_result = result\n",
    "print()        \n",
    "print(\"F1 score лучшей модели дерева решений на валидационной выборке:\", best_tree_result, \", с глубиной\", best_tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "tree.plot_tree(best_tree_model,fontsize=10, feature_names = features.columns, class_names = ['Exited', 'Not Exited'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_predictions = best_tree_model.predict(features_valid)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(target_valid, best_tree_predictions))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest_model = None\n",
    "best_forest_result = 0\n",
    "best_forest_depth = 0\n",
    "best_forest_est = 0\n",
    "\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range (1, 11):\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=est,max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions = model.predict(features_valid) \n",
    "        result = f1_score(target_valid, predictions)\n",
    "        if result > best_forest_result:\n",
    "            best_forest_model = model\n",
    "            best_forest_result = result\n",
    "            best_forest_est = est\n",
    "            best_forest_depth = depth\n",
    "\n",
    "print('F1 score лучшей модели случайный лес:',best_forest_result, \",\", \"с глубиной\", best_forest_depth, \"и числом деревьев\", best_forest_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest_predictions = best_forest_model.predict(features_valid)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(target_valid, best_forest_predictions))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(random_state=RANDOM_STATE, solver='lbfgs', max_iter=1000)\n",
    "log_model.fit(features_train, target_train)\n",
    "dump(model, 'model_9_1.joblib')\n",
    "predictions = log_model.predict(features_valid) \n",
    "log_model_result = f1_score(target_valid, predictions)\n",
    "print('F1 score модели логистическая регрессия:',log_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_predictions = log_model.predict(features_valid)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(target_valid, log_predictions))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по исследованию моделей без учета дизбаланса\n",
    "\n",
    "- F1 score лучшей модели дерева решений на валидационной выборке: 0.57\n",
    "- F1 score лучшей модели случайный лес: 0.57\n",
    "- F1 score модели логистическая регрессия: 0.30\n",
    "\n",
    "Для всех моделей F1 score не дотягивает до 0.59. Построив матрицу истинно отрицательных, истинно положительных, ложно отрицательных и ложно положительных ответов для каждой модели, мы видим, что дизбаланс классов дейсвительно сказывается на поведении модели - она делает много ошибок в предсказании класса 1 (то есть покинувшие банк клиенты), который нам интересен. \n",
    "\n",
    "Попробуем решить проблему дизбаланса.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дизбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опробуем три метода борьбы с дизбалансом - \n",
    "1) взвешивание классов <br>\n",
    "2) увеличение выборки за счет дублирования редкого класса (upsampling) <br>\n",
    "3) уменьшение выборки за счет отбрасывание частого класса (downsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опробуем те же три модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_model = None\n",
    "best_tree_result = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 15):\n",
    "    model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=depth, class_weight='balanced') #опробуем глубину дерева от 1 до 15\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid) \n",
    "    result = f1_score(target_valid, predictions)\n",
    "    if result > best_tree_result:\n",
    "        best_tree_model = model\n",
    "        best_tree_depth = depth\n",
    "        best_tree_result = result\n",
    "print()        \n",
    "print(\"F1 score лучшей модели дерева решений на валидационной выборке:\", best_tree_result, \", с глубиной\", best_tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest_model = None\n",
    "best_forest_result = 0\n",
    "best_forest_depth = 0\n",
    "best_forest_est = 0\n",
    "\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range (1, 11):\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=est,max_depth=depth, class_weight='balanced')\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions = model.predict(features_valid) \n",
    "        result = f1_score(target_valid, predictions)\n",
    "        if result > best_forest_result:\n",
    "            best_forest_model = model\n",
    "            best_forest_result = result\n",
    "            best_forest_est = est\n",
    "            best_forest_depth = depth\n",
    "\n",
    "print('F1 score лучшей модели случайный лес:',best_forest_result, \",\", \"с глубиной\", best_forest_depth, \"и числом деревьев\", best_forest_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(random_state=RANDOM_STATE, solver='lbfgs', max_iter=1000, class_weight='balanced')\n",
    "log_model.fit(features_train, target_train)\n",
    "dump(model, 'model_9_1.joblib')\n",
    "predictions = log_model.predict(features_valid) \n",
    "log_model_result = f1_score(target_valid, predictions)\n",
    "print('F1 score модели логистическая регрессия:',log_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы по результам моделей с взвешиванием классов:** <br>\n",
    "    - На F1 score дерева решений взвешивание классов почти не повлияло <br>\n",
    "    - Взвешивание классов повысило F1 score случайного леса до 0.64, что выше 0.59 на валидационной выборке <br>\n",
    "    - Взвешивание классов также повысило F1 score логистической регрессии с 0.3 до 0.5!<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=RANDOM_STATE)\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.reset_index(drop = True, inplace = True)\n",
    "target_train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsample, target_upsample = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_upsample.sum()/len(target_upsample)\n",
    "\n",
    "# Теперь баланс классов 1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на три наши модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_model = None\n",
    "best_tree_result = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 15):\n",
    "    model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=depth, class_weight='balanced') #опробуем глубину дерева от 1 до 15\n",
    "    model.fit(features_upsample, target_upsample)\n",
    "    predictions = model.predict(features_valid) \n",
    "    result = f1_score(target_valid, predictions)\n",
    "    if result > best_tree_result:\n",
    "        best_tree_model = model\n",
    "        best_tree_depth = depth\n",
    "        best_tree_result = result\n",
    "print()        \n",
    "print(\"F1 score лучшей модели дерева решений на валидационной выборке:\", best_tree_result, \", с глубиной\", best_tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest_model = None\n",
    "best_forest_result = 0\n",
    "best_forest_depth = 0\n",
    "best_forest_est = 0\n",
    "\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range (1, 11):\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=est,max_depth=depth, class_weight='balanced')\n",
    "        model.fit(features_upsample, target_upsample)\n",
    "        predictions = model.predict(features_valid) \n",
    "        result = f1_score(target_valid, predictions)\n",
    "        if result > best_forest_result:\n",
    "            best_forest_model = model\n",
    "            best_forest_result = result\n",
    "            best_forest_est = est\n",
    "            best_forest_depth = depth\n",
    "\n",
    "print('F1 score лучшей модели случайный лес:',best_forest_result, \",\", \"с глубиной\", best_forest_depth, \"и числом деревьев\", best_forest_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(random_state=RANDOM_STATE, solver='lbfgs', max_iter=1000, class_weight='balanced')\n",
    "log_model.fit(features_upsample, target_upsample)\n",
    "dump(model, 'model_9_1.joblib')\n",
    "predictions = log_model.predict(features_valid) \n",
    "log_model_result = f1_score(target_valid, predictions)\n",
    "print('F1 score модели логистическая регрессия:',log_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "**Выводы по результам моделей с взвешиванием классов:** <br>\n",
    "  Для модели случайного леса F1 score повысился выше нужного нам порога! <br>\n",
    "- F1 score лучшей модели дерева решений на валидационной выборке: 0.57\n",
    "- F1 score лучшей модели случайный лес: 0.63\n",
    "- F1 score модели логистическая регрессия: 0.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_downsampled = pd.concat(\n",
    "    [features_zeros.sample(frac=fraction, random_state=RANDOM_STATE)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "    [target_zeros.sample(frac=fraction, random_state=RANDOM_STATE)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "    features_downsampled, target_downsampled, random_state=RANDOM_STATE)\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsample, target_downsample = downsample(features_train, target_train, 1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_downsample.sum()/len(target_downsample)\n",
    "\n",
    "# Теперь баланс классов 1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_model = None\n",
    "best_tree_result = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 15):\n",
    "    model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=depth, class_weight='balanced') #опробуем глубину дерева от 1 до 15\n",
    "    model.fit(features_downsample, target_downsample)\n",
    "    predictions = model.predict(features_valid) \n",
    "    result = f1_score(target_valid, predictions)\n",
    "    if result > best_tree_result:\n",
    "        best_tree_model = model\n",
    "        best_tree_depth = depth\n",
    "        best_tree_result = result\n",
    "print()        \n",
    "print(\"F1 score лучшей модели дерева решений на валидационной выборке:\", best_tree_result, \", с глубиной\", best_tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest_model = None\n",
    "best_forest_result = 0\n",
    "best_forest_depth = 0\n",
    "best_forest_est = 0\n",
    "\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range (1, 11):\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=est,max_depth=depth, class_weight='balanced')\n",
    "        model.fit(features_downsample, target_downsample)\n",
    "        predictions = model.predict(features_valid) \n",
    "        result = f1_score(target_valid, predictions)\n",
    "        if result > best_forest_result:\n",
    "            best_forest_model = model\n",
    "            best_forest_result = result\n",
    "            best_forest_est = est\n",
    "            best_forest_depth = depth\n",
    "\n",
    "print('F1 score лучшей модели случайный лес:',best_forest_result, \",\", \"с глубиной\", best_forest_depth, \"и числом деревьев\", best_forest_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(random_state=RANDOM_STATE, solver='lbfgs', max_iter=1000, class_weight='balanced')\n",
    "log_model.fit(features_downsample, target_downsample)\n",
    "dump(model, 'model_9_1.joblib')\n",
    "predictions = log_model.predict(features_valid) \n",
    "log_model_result = f1_score(target_valid, predictions)\n",
    "print('F1 score модели логистическая регрессия:',log_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "**Выводы по результам моделей с взвешиванием классов:** <br>\n",
    "  Уменьшение выборки показало результат чуть хуже, чем увеличение выборки, что, наверное, неудивительно, ведь тамким образом мы подаем в модель меньше данных. <br>\n",
    "- F1 score лучшей модели дерева решений на валидационной выборке: 0.57\n",
    "- F1 score лучшей модели случайный лес: 0.59\n",
    "- F1 score модели логистическая регрессия: 0.50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод по дизбалансу классов:** <br>\n",
    "\n",
    "Из трех опробованных методов балансирования классов лучший результат показало увеличение выборки (upsampling). Лучший результат при этом показала модель случайного леса с результатом 0.63 на валидационной выборке. Это модель с глубиной 9 и числом деревьев 40.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=40,max_depth=9, class_weight='balanced')\n",
    "final_model.fit(features_upsample, target_upsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Теперь проведем тестирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_forest = final_model.predict(features_test) \n",
    "result_forest = f1_score(target_test, predictions_forest)\n",
    "print('F1 score лучшей модели случайный лес на тестовой выборке:',result_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Исследуем метрику AUC-ROC победившей модели **случайного леса с F1 score 0.594** на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(target_test, predictions_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_test = final_model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)# < напишите код здесь >\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# ROC-кривая случайной модели\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша ROC-кривая близится к идеалу, а ROC-AUC достаточно близко к единице - 0.77\n",
    "\n",
    "Модель готова!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
